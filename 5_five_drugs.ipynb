{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Collect the tweets of the first five kinds of drugs.\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import tqdm \n",
    "out_dir = '/data1/data_8t/ivermectin/sentiment/' #Saving path\n",
    "data_type = {'created_at':'string','id':'string','full_text':'string','user':'object',\"extracted_entity_sentiment\":'object','drug_entity':'object',\"sentiment\":'object'}\n",
    "#Create file name list\n",
    "import glob\n",
    "import pandas as pd\n",
    "import tqdm   ## this is a ticker\n",
    "data_dir = \"/data1/data_8t/ivermectin/sentiment/drug+senti/\" \n",
    "files = sorted(glob.glob(data_dir+\"*.csv\"))\n",
    "file = '|'.join(files) #Change the list to string\n",
    "keys='vitamin d|Vitamin D2|Vitamin D3|vd3|vd2' #The keywords you want to search with VD as the example\n",
    "\n",
    "def parallelize_dataframe(df, func, **kwargs):\n",
    "    #CPUs = multiprocessing.cpu_count()\n",
    "    num_partitions = 8 # number of partitions to split dataframe\n",
    "    num_cores =  8 # number of cores on your machine\n",
    "\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = Pool(num_cores)\n",
    "    func = partial(func, **kwargs)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "    \n",
    "def extract(df,keys):\n",
    "    keys=keys\n",
    "    \n",
    "    # #keyword string\n",
    "    # keywords = pd.read_csv('/data_8t/lwx/keywords/keywords.csv')\n",
    "    # keys = keywords.Drugs.tolist()  # to list\n",
    "    # keys = '|'.join(keys) # to string\n",
    "\n",
    "    #df = df[df['full_text'].str.contains(fr\"\\b(?:{keys})\\b\",case=False,flags=re.I)] #filter the data with keys\n",
    "    # flag=df['symp_entity'].str.contains(fr\"\\b(?:{keys})\\b\",case=False,flags=re.I)\n",
    "    # diff_flag = [not f for f in flag]\n",
    "    # res = df[diff_flag]\n",
    "    # res=res.reset_index(drop=True)\n",
    "    df = df[df['drug_entity'].str.contains(fr\"\\b(?:{keys})\\b\",case=False,flags=re.I)] #filter the data with keys\n",
    "    #print(len(df))\n",
    "    df1 = df.drop_duplicates(subset=['id']) #drop the duplicates\n",
    "    return df1\n",
    "\n",
    "\n",
    "df_empty = pd.DataFrame(columns=[\"created_at\",\"id\",\"full_text\",\"user\",'drug_entity','sentiment'])\n",
    "for file in tqdm.tqdm(files):\n",
    "    df = pd.read_csv(file,dtype=data_type, lineterminator='\\n',usecols=['created_at','id','full_text','user','drug_entity','sentiment'],low_memory=False, keep_default_na=False)#, iterator=True,chunksize=100000)\n",
    "    df1=extract(df,keys)\n",
    "    #df1 = parallelize_dataframe(df, extract)\n",
    "    df_empty=pd.concat([df_empty,df1])\n",
    "#keys='vitamin d|Vitamin D2|Vitamin D3|vd3|vd2|vit d|Calcifediol'\n",
    "df_empty.to_csv(out_dir+keys+\".csv\",index=False)  #Save the data\n",
    "print(len(df_empty))\n",
    "# Decriptive Statistics for the sentiment\n",
    "\n",
    "import pandas as pd\n",
    "symp=[]\n",
    "df = pd.read_csv(\"/data1/data_8t/ivermectin/sentiment/zinc.csv\",lineterminator='\\n',low_memory=False, keep_default_na=False)\n",
    "s=df['sentiment'].tolist()\n",
    "symp.extend(s)\n",
    "a=[]\n",
    "for i in symp:\n",
    "    b=(i[1:-1])\n",
    "    if b!='':\n",
    "       a.append((eval(b)))\n",
    "\n",
    "b=[]\n",
    "for i in a:\n",
    "    if type(i)==tuple:\n",
    "        i=list(i)\n",
    "        for ii in i:\n",
    "            #print(type(ii),ii)\n",
    "            b.append(ii)\n",
    "    else:\n",
    "        #print(type(i),i)\n",
    "        b.append(i)\n",
    "dict = {}\n",
    "for key in b:\n",
    "    dict[key] = dict.get(key, 0) + 1\n",
    "print(dict)\n",
    "#### Extract the number of emotions related to the drugs in each tweet.\n",
    "def Getsenti_num(twt):\n",
    "    n=twt.count(',')+1\n",
    "    return n\n",
    "\n",
    "def Getpos_num(twt):\n",
    "    n=twt.count('positive')\n",
    "    return n\n",
    "\n",
    "def Getneg_num(twt):\n",
    "    n=twt.count('negative')\n",
    "    return n\n",
    "\n",
    "def Getneu_num(twt):\n",
    "    n=twt.count('neutral')\n",
    "    return n\n",
    "\n",
    "def Senti_Entity(entity):#Extract the \"drug\" entity in the entity extraction part.\n",
    "    senti_entity = []\n",
    "    try:\n",
    "        for i in eval(entity): \n",
    "            if i['type'] == 'Drug' and 'sentiment' in i:\n",
    "                senti_entity.append(i['sentiment'].lower())\n",
    "        return senti_entity\n",
    "    except TypeError: # because some users has no text\n",
    "        return '[]'\n",
    "\n",
    "def parall_func(df):\n",
    "    df['senti_num'] = df['sentiment'].apply(Getsenti_num)\n",
    "    df['pos_num'] = df['sentiment'].apply(Getpos_num)\n",
    "    df['neg_num'] = df['sentiment'].apply(Getneg_num)\n",
    "    df['neu_num'] = df['sentiment'].apply(Getneu_num)\n",
    "    return df\n",
    "\n",
    "\n",
    "#pattern = re.compile('|'.join(symptom_keywords),flags=re.I)\n",
    "# This function is used for multi-threading. The input is the data frame you want to process and the corresponding function.\n",
    "def parallelize_dataframe(df, func, **kwargs):\n",
    "    #CPUs = multiprocessing.cpu_count()\n",
    "    num_partitions = 4 # number of partitions to split dataframe\n",
    "    num_cores =  4 # number of cores on your machine\n",
    "\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = Pool(num_cores)\n",
    "    func = partial(func, **kwargs)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "'''\n",
    "# find the keywords in the text. if a keyword appears \n",
    "# several time in a text, only return one of it.\n",
    "'''\n",
    "df = pd.read_csv('/data1/data_8t/ivermectin/sentiment/vitamin d|Vitamin D2|Vitamin D3|vd3|vd2.csv',lineterminator='\\n',low_memory=False)\n",
    "df = parallelize_dataframe(df, parall_func)\n",
    "df.to_csv('/data1/data_8t/ivermectin/sentiment/vitamin d|Vitamin D2|Vitamin D3|vd3|vd2.csv')\n",
    "#Calculate the proportion of \"positive\" in the weekly tweets regarding zinc.\n",
    "import pandas as pd\n",
    "df=pd.read_csv('zinc.csv')\n",
    "data=df[['created_at','pos_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqzincp.csv')\n",
    "#And then divide it by the total number of entities per week.\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('zinc.csv')\n",
    "data=df[['created_at','neg_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqzincn.csv')\n",
    "#And then divide it by the total number of entities per week.\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('zinc.csv')\n",
    "data=df[['created_at','senti_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqzincs.csv')\n",
    "# Calculate the proportion of \"positive\" in the weekly tweets regarding HCQ.\n",
    "import pandas as pd\n",
    "df=pd.read_csv('/data1/data_8t/ivermectin/sentiment/Hydroxychloroquine|HCQ|plaquenil.csv')\n",
    "data=df[['created_at','pos_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqhcqp.csv')\n",
    "#And then divide it by the total number of entities per week.\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('hcq.csv')\n",
    "data=df[['created_at','neg_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqhcqn.csv')\n",
    "#And then divide it by the total number of entities per week.\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('hcq.csv')\n",
    "data=df[['created_at','senti_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqhcqs.csv')\n",
    "# Calculate the proportion of \"positive\" in the weekly tweets regarding Ivermectin.\n",
    "import pandas as pd\n",
    "df=pd.read_csv('zinc.csv')\n",
    "data=df[['created_at','pos_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqzincp.csv')\n",
    "#And then divide it by the total number of entities per week.\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('zinc.csv')\n",
    "data=df[['created_at','neg_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqzincn.csv')\n",
    "#And then divide it by the total number of entities per week.\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('zinc.csv')\n",
    "data=df[['created_at','senti_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqzincs.csv')\n",
    "# Calculate the proportion of \"positive\" in the weekly tweets regarding Remdesivir.\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/data1/data_8t/ivermectin/sentiment/Remdesivir|velkury.csv',lineterminator='\\n',low_memory=False)\n",
    "data=df[['created_at','pos_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqremp.csv')\n",
    "#And then divide it by the total number of entities per week.\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('rem.csv')\n",
    "data=df[['created_at','neg_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqremn.csv')\n",
    "#And then divide it by the total number of entities per week.\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('rem.csv')\n",
    "data=df[['created_at','senti_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqrems.csv')\n",
    "import pandas as pd\n",
    "df=pd.read_csv('/data1/data_8t/ivermectin/sentiment/vitamin d|Vitamin D2|Vitamin D3|vd3|vd2.csv')\n",
    "data=df[['created_at','pos_num']]\n",
    "data.to_csv('vitd_senti.csv',index=False)\n",
    "# Calculate the proportion of \"positive\" in the weekly tweets regarding Vitamin D.\n",
    "data=pd.read_csv('vitd_senti.csv')\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqvitdp.csv')\n",
    "#And then divide it by the total number of entities per week.\n",
    "\n",
    "import pandas as pd\n",
    "data=pd.read_csv('vitd_senti.csv')\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqvitdn.csv')\n",
    "#And then divide it by the total number of entities per week.\n",
    "\n",
    "import pandas as pd\n",
    "data=pd.read_csv('vitd_senti.csv')\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqvitds.csv')\n",
    "# Calculate the proportion of \"positive\" in the weekly tweets regarding Ivermectin.\n",
    "import pandas as pd\n",
    "df=pd.read_csv('/data1/data_8t/ivermectin/sentiment/ivermectin|Stromectol.csv')\n",
    "data=df[['created_at','pos_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqiverp.csv')\n",
    "#And then divide it by the total number of entities per week.\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('iver.csv')\n",
    "data=df[['created_at','neg_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqivern.csv')\n",
    "#And then divide it by the total number of entities per week.\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('iver.csv')\n",
    "data=df[['created_at','senti_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqivers.csv')\n",
    "# Calculate the proportion of \"positive\" in the weekly tweets regarding Ivermectin.\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/data1/data_8t/ivermectin/sentiment/vitamin d|Vitamin D2|Vitamin D3|vd3|vd2.csv',lineterminator='\\n',low_memory=False)\n",
    "df = parallelize_dataframe(df, parall_func)\n",
    "df.to_csv('/data1/data_8t/ivermectin/sentiment/vitamin d|Vitamin D2|Vitamin D3|vd3|vd2.csv',index=False)\n",
    "data=df[['created_at','pos_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqvitdp.csv')\n",
    "#And then divide it by the total number of entities per week.\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('iver.csv')\n",
    "data=df[['created_at','neg_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqvitdn.csv')\n",
    "#And then divide it by the total number of entities per week.\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('iver.csv')\n",
    "data=df[['created_at','senti_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqvitds.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
