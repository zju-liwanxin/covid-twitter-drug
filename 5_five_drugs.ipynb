{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将前五种药物的推特都收集出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "import multiprocessing\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import tqdm \n",
    "out_dir = '/data1/data_8t/ivermectin/sentiment/' #保存文件的位置\n",
    "data_type = {'created_at':'string','id':'string','full_text':'string','user':'object',\"extracted_entity_sentiment\":'object','drug_entity':'object',\"sentiment\":'object'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建文件名列表\n",
    "import glob\n",
    "import pandas as pd\n",
    "import tqdm   ## this is a ticker\n",
    "data_dir = \"/data1/data_8t/ivermectin/sentiment/drug+senti/\" \n",
    "files = sorted(glob.glob(data_dir+\"*.csv\"))\n",
    "file = '|'.join(files) #转为字符串"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:50<00:00,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86028\n"
     ]
    }
   ],
   "source": [
    "keys='vitamin d|Vitamin D2|Vitamin D3|vd3|vd2' #五种药物的keyword 以vd为例\n",
    "\n",
    "def parallelize_dataframe(df, func, **kwargs):\n",
    "    #CPUs = multiprocessing.cpu_count()\n",
    "    num_partitions = 8 # number of partitions to split dataframe\n",
    "    num_cores =  8 # number of cores on your machine\n",
    "\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = Pool(num_cores)\n",
    "    func = partial(func, **kwargs)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "    \n",
    "def extract(df,keys):\n",
    "    keys=keys\n",
    "    \n",
    "    # #关键词字符串\n",
    "    # keywords = pd.read_csv('/data_8t/lwx/keywords/keywords.csv')\n",
    "    # keys = keywords.Drugs.tolist()  #转为列表\n",
    "    # keys = '|'.join(keys) #转为字符串\n",
    "\n",
    "    #df = df[df['full_text'].str.contains(fr\"\\b(?:{keys})\\b\",case=False,flags=re.I)] #筛选包含keys的数据\n",
    "    # flag=df['symp_entity'].str.contains(fr\"\\b(?:{keys})\\b\",case=False,flags=re.I)\n",
    "    # diff_flag = [not f for f in flag]\n",
    "    # res = df[diff_flag]\n",
    "    # res=res.reset_index(drop=True)\n",
    "    df = df[df['drug_entity'].str.contains(fr\"\\b(?:{keys})\\b\",case=False,flags=re.I)] #筛选包含keys的数据\n",
    "    #print(len(df))\n",
    "    df1 = df.drop_duplicates(subset=['id']) #去除重复项\n",
    "    return df1\n",
    "\n",
    "\n",
    "df_empty = pd.DataFrame(columns=[\"created_at\",\"id\",\"full_text\",\"user\",'drug_entity','sentiment'])\n",
    "for file in tqdm.tqdm(files):\n",
    "    df = pd.read_csv(file,dtype=data_type, lineterminator='\\n',usecols=['created_at','id','full_text','user','drug_entity','sentiment'],low_memory=False, keep_default_na=False)#, iterator=True,chunksize=100000)\n",
    "    df1=extract(df,keys)\n",
    "    #df1 = parallelize_dataframe(df, extract)\n",
    "    df_empty=pd.concat([df_empty,df1])\n",
    "#keys='vitamin d|Vitamin D2|Vitamin D3|vd3|vd2|vit d|Calcifediol'\n",
    "df_empty.to_csv(out_dir+keys+\".csv\",index=False)  #保存文件\n",
    "print(len(df_empty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'positive': 130206, 'neutral': 154257, 'negative': 3468}\n"
     ]
    }
   ],
   "source": [
    "# 统计所有的积极消极中性情绪占比\n",
    "\n",
    "import pandas as pd\n",
    "symp=[]\n",
    "df = pd.read_csv(\"/data1/data_8t/ivermectin/sentiment/zinc.csv\",lineterminator='\\n',low_memory=False, keep_default_na=False)\n",
    "s=df['sentiment'].tolist()\n",
    "symp.extend(s)\n",
    "a=[]\n",
    "for i in symp:\n",
    "    b=(i[1:-1])\n",
    "    if b!='':\n",
    "       a.append((eval(b)))\n",
    "\n",
    "b=[]\n",
    "for i in a:\n",
    "    if type(i)==tuple:\n",
    "        i=list(i)\n",
    "        for ii in i:\n",
    "            #print(type(ii),ii)\n",
    "            b.append(ii)\n",
    "    else:\n",
    "        #print(type(i),i)\n",
    "        b.append(i)\n",
    "dict = {}\n",
    "for key in b:\n",
    "    dict[key] = dict.get(key, 0) + 1\n",
    "print(dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 将每条推特中药物的情感个数提取出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# find the keywords in the text. if a keyword appears \\n# several time in a text, only return one of it.\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def Getsenti_num(twt):\n",
    "    n=twt.count(',')+1\n",
    "    return n\n",
    "\n",
    "def Getpos_num(twt):\n",
    "    n=twt.count('positive')\n",
    "    return n\n",
    "\n",
    "def Getneg_num(twt):\n",
    "    n=twt.count('negative')\n",
    "    return n\n",
    "\n",
    "def Getneu_num(twt):\n",
    "    n=twt.count('neutral')\n",
    "    return n\n",
    "\n",
    "def Senti_Entity(entity):#实体提取部分提取出drug实体\n",
    "    senti_entity = []\n",
    "    try:\n",
    "        for i in eval(entity): \n",
    "            if i['type'] == 'Drug' and 'sentiment' in i:\n",
    "                senti_entity.append(i['sentiment'].lower())\n",
    "        return senti_entity\n",
    "    except TypeError: # because some users has no text\n",
    "        return '[]'\n",
    "\n",
    "def parall_func(df):\n",
    "    df['senti_num'] = df['sentiment'].apply(Getsenti_num)\n",
    "    df['pos_num'] = df['sentiment'].apply(Getpos_num)\n",
    "    df['neg_num'] = df['sentiment'].apply(Getneg_num)\n",
    "    df['neu_num'] = df['sentiment'].apply(Getneu_num)\n",
    "    return df\n",
    "\n",
    "\n",
    "#pattern = re.compile('|'.join(symptom_keywords),flags=re.I)\n",
    "# 这个函数就是用来做多线程的，输入是你要处理的数据框和相应的函数\n",
    "def parallelize_dataframe(df, func, **kwargs):\n",
    "    #CPUs = multiprocessing.cpu_count()\n",
    "    num_partitions = 4 # number of partitions to split dataframe\n",
    "    num_cores =  4 # number of cores on your machine\n",
    "\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = Pool(num_cores)\n",
    "    func = partial(func, **kwargs)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "'''\n",
    "# find the keywords in the text. if a keyword appears \n",
    "# several time in a text, only return one of it.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/data1/data_8t/ivermectin/sentiment/vitamin d|Vitamin D2|Vitamin D3|vd3|vd2.csv',lineterminator='\\n',low_memory=False)\n",
    "df = parallelize_dataframe(df, parall_func)\n",
    "df.to_csv('/data1/data_8t/ivermectin/sentiment/vitamin d|Vitamin D2|Vitamin D3|vd3|vd2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4168934/3533757849.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'] = pd.to_datetime(data['created_at'])\n",
      "/tmp/ipykernel_4168934/3533757849.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'] = pd.to_datetime(data['created_at'])\n",
      "/tmp/ipykernel_4168934/3533757849.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'] = pd.to_datetime(data['created_at'])\n"
     ]
    }
   ],
   "source": [
    "#对于zinc 计算每周推文中positive的比例\n",
    "import pandas as pd\n",
    "df=pd.read_csv('zinc.csv')\n",
    "data=df[['created_at','pos_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqzincp.csv')\n",
    "#再除以每周实体总数\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('zinc.csv')\n",
    "data=df[['created_at','neg_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqzincn.csv')\n",
    "#再除以每周实体总数\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('zinc.csv')\n",
    "data=df[['created_at','senti_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqzincs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9324/1867587130.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'] = pd.to_datetime(data['created_at'])\n",
      "/tmp/ipykernel_9324/1867587130.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'] = pd.to_datetime(data['created_at'])\n",
      "/tmp/ipykernel_9324/1867587130.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'] = pd.to_datetime(data['created_at'])\n"
     ]
    }
   ],
   "source": [
    "# 对于HCQ\n",
    "import pandas as pd\n",
    "df=pd.read_csv('/data1/data_8t/ivermectin/sentiment/Hydroxychloroquine|HCQ|plaquenil.csv')\n",
    "data=df[['created_at','pos_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqhcqp.csv')\n",
    "#再除以每周实体总数\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('hcq.csv')\n",
    "data=df[['created_at','neg_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqhcqn.csv')\n",
    "#再除以每周实体总数\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('hcq.csv')\n",
    "data=df[['created_at','senti_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqhcqs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于zinc\n",
    "import pandas as pd\n",
    "df=pd.read_csv('zinc.csv')\n",
    "data=df[['created_at','pos_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqzincp.csv')\n",
    "#再除以每周实体总数\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('zinc.csv')\n",
    "data=df[['created_at','neg_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqzincn.csv')\n",
    "#再除以每周实体总数\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('zinc.csv')\n",
    "data=df[['created_at','senti_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqzincs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4168934/2750269058.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'] = pd.to_datetime(data['created_at'])\n",
      "/tmp/ipykernel_4168934/2750269058.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'] = pd.to_datetime(data['created_at'])\n",
      "/tmp/ipykernel_4168934/2750269058.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'] = pd.to_datetime(data['created_at'])\n"
     ]
    }
   ],
   "source": [
    "# 对于remdesivir\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/data1/data_8t/ivermectin/sentiment/Remdesivir|velkury.csv',lineterminator='\\n',low_memory=False)\n",
    "data=df[['created_at','pos_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqremp.csv')\n",
    "#再除以每周实体总数\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('rem.csv')\n",
    "data=df[['created_at','neg_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqremn.csv')\n",
    "#再除以每周实体总数\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('rem.csv')\n",
    "data=df[['created_at','senti_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqrems.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('/data1/data_8t/ivermectin/sentiment/vitamin d|Vitamin D2|Vitamin D3|vd3|vd2.csv')\n",
    "data=df[['created_at','pos_num']]\n",
    "data.to_csv('vitd_senti.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对vitd\n",
    "data=pd.read_csv('vitd_senti.csv')\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqvitdp.csv')\n",
    "#再除以每周实体总数\n",
    "\n",
    "import pandas as pd\n",
    "data=pd.read_csv('vitd_senti.csv')\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqvitdn.csv')\n",
    "#再除以每周实体总数\n",
    "\n",
    "import pandas as pd\n",
    "data=pd.read_csv('vitd_senti.csv')\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqvitds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9324/3188282339.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'] = pd.to_datetime(data['created_at'])\n",
      "/tmp/ipykernel_9324/3188282339.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'] = pd.to_datetime(data['created_at'])\n",
      "/tmp/ipykernel_9324/3188282339.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'] = pd.to_datetime(data['created_at'])\n"
     ]
    }
   ],
   "source": [
    "# 对ivermectin\n",
    "import pandas as pd\n",
    "df=pd.read_csv('/data1/data_8t/ivermectin/sentiment/ivermectin|Stromectol.csv')\n",
    "data=df[['created_at','pos_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqiverp.csv')\n",
    "#再除以每周实体总数\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('iver.csv')\n",
    "data=df[['created_at','neg_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqivern.csv')\n",
    "#再除以每周实体总数\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('iver.csv')\n",
    "data=df[['created_at','senti_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqivers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9324/3129157154.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'] = pd.to_datetime(data['created_at'])\n",
      "/tmp/ipykernel_9324/3129157154.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'] = pd.to_datetime(data['created_at'])\n",
      "/tmp/ipykernel_9324/3129157154.py:31: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['created_at'] = pd.to_datetime(data['created_at'])\n"
     ]
    }
   ],
   "source": [
    "# 对vitd\n",
    "import pandas as pd\n",
    "df = pd.read_csv('/data1/data_8t/ivermectin/sentiment/vitamin d|Vitamin D2|Vitamin D3|vd3|vd2.csv',lineterminator='\\n',low_memory=False)\n",
    "df = parallelize_dataframe(df, parall_func)\n",
    "df.to_csv('/data1/data_8t/ivermectin/sentiment/vitamin d|Vitamin D2|Vitamin D3|vd3|vd2.csv',index=False)\n",
    "data=df[['created_at','pos_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqvitdp.csv')\n",
    "#再除以每周实体总数\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('iver.csv')\n",
    "data=df[['created_at','neg_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqvitdn.csv')\n",
    "#再除以每周实体总数\n",
    "\n",
    "import pandas as pd\n",
    "#df=pd.read_csv('iver.csv')\n",
    "data=df[['created_at','senti_num']]\n",
    "data['created_at'] = pd.to_datetime(data['created_at'])\n",
    "data.index = data['created_at']\n",
    "data=data.sort_index()\n",
    "#del data['created_at']\n",
    "#data.insert(data.shape[1], 'd', 1)\n",
    "p=data.resample('W', label='right', closed='right').sum()\n",
    "p.to_csv('freqvitds.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('lwx')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "765ef3d65742a26d9e89c0bc1eecd9f137f8dcbf3a9b284d9226ff30499408a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
